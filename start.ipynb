{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from string import Template\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "load_dotenv();\n",
    "assert(os.getenv(\"PAT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['j-autoworker-0                             0/1           79s        79s']\n",
      "Number of active jobs: 0\n"
     ]
    }
   ],
   "source": [
    "def count_active_jobs():\n",
    "  cmd = \"kubectl get jobs\"\n",
    "  stream = os.popen(cmd)\n",
    "  output = stream.read()\n",
    "  splits = filter(lambda x : re.search(\"^j-autoworker-\", x), output.split(\"\\n\"))\n",
    "  print(list(splits))\n",
    "  return len(list(splits))\n",
    "print(f\"Number of active jobs: {count_active_jobs()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_job(yaml_data):\n",
    "  p = Popen([\"kubectl\", \"apply\", \"-f\", \"-\"], shell=True, stdout=PIPE, stderr=PIPE, stdin=PIPE)\n",
    "  output = p.communicate(input=bytes(yaml_data, encoding=\"utf-8\"))\n",
    "  output = [line.decode() for line in output if line]\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===py_template.yml===\n",
      "apiVersion: batch/v1\n",
      "kind: Job\n",
      "metadata:\n",
      "  name: j-autoworker-0\n",
      "  namespace: guru-research\n",
      "spec:\n",
      "  template:\n",
      "    spec:\n",
      "      affinity:\n",
      "        nodeAffinity:\n",
      "          requiredDuringSchedulingIgnoredDuringExecution:\n",
      "            nodeSelectorTerms:\n",
      "              - matchExpressions:\n",
      "                  - key: kubernetes.io/hostname\n",
      "                    operator: NotIn\n",
      "                    values:\n",
      "                      - perfsonar.csusb.edu\n",
      "                      - prp-gpu-3.t2.ucsd.edu\n",
      "      containers:\n",
      "        - name: demo\n",
      "          image: jamesjzhao01/smart:latest\n",
      "          command: [\"/bin/bash\"]\n",
      "          args:\n",
      "            - \"-c\"\n",
      "            - >-\n",
      "              cd /workspace && git clone\n",
      "              https://jameszhao01:${PAT}@github.com/Cyoung02/smart4.5.git && cd\n",
      "              /workspace/smart4.5 && scripts/pull_dataset.sh SMILES_dataset &&\n",
      "              scripts/pull_dataset.sh SMILES_ranking_sets &&\n",
      "              scripts/pull_chemformer.sh && scripts/worker.sh && python\n",
      "              train_concise.py --config configs/clip/simple_clip.yml\n",
      "          volumeMounts:\n",
      "            - name: james-shared\n",
      "              mountPath: /data\n",
      "            - name: dshm\n",
      "              mountPath: /dev/shm\n",
      "          resources:\n",
      "            limits:\n",
      "              memory: 16Gi\n",
      "              cpu: \"12\"\n",
      "              nvidia.com/gpu: \"1\"\n",
      "            requests:\n",
      "              memory: 16Gi\n",
      "              cpu: \"12\"\n",
      "              nvidia.com/gpu: \"1\"\n",
      "          env:\n",
      "            - name: PAT\n",
      "              value: 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\n",
      "      volumes:\n",
      "        - name: james-shared\n",
      "          persistentVolumeClaim:\n",
      "            claimName: james-shared\n",
      "        - name: dshm\n",
      "          emptyDir:\n",
      "            medium: Memory\n",
      "      restartPolicy: Never\n",
      "  backoffLimit: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "configs_path = \"smart4.5/configs/clip/*\"\n",
    "template_path = \"py_template.yml\"\n",
    "pat = os.getenv(\"PAT\")\n",
    "dry_run = False\n",
    "\n",
    "for i, path in enumerate(glob.glob(configs_path)):\n",
    "  path = Path(path)\n",
    "  path_small = Path(*path.parts[1:])\n",
    "  if dry_run:\n",
    "    print(\"dry_run\", path)\n",
    "  else:\n",
    "    with open(template_path, \"r\") as f:\n",
    "      contents = f.read()\n",
    "      template = Template(contents)\n",
    "      template = template.safe_substitute(pat=pat, config=path_small.as_posix(), i=i)\n",
    "      output = create_job(template)\n",
    "      print(f\"==={template_path}===\")\n",
    "      # print(template)\n",
    "      print(\"\\t\", output)\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
